{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  # таблицы\n",
    "from collections import Counter  # счетчики\n",
    "import datetime  # даты\n",
    "import nltk # униграммы\n",
    "\n",
    "dir = \"D:\\HSE\\Pump_Dump\\\\\"  # папка проекта\n",
    "\n",
    "# фрейм ЦБ ММВБ\n",
    "shares_pd = pd.read_csv(dir + \"market\\\\moex_cb.csv\", sep=\",\", encoding=\"utf-8\")\n",
    "shares_pd = shares_pd[(shares_pd[\"SUPERTYPE\"] == \"Акции\")]\n",
    "shares_pd.dropna(subset=\"INN\", axis=0, inplace=True)\n",
    "# удаляем строки без тикеров\n",
    "shares_pd.dropna(subset=\"TRADE_CODE\", axis=0, inplace=True)\n",
    "# Тикеры к нижнему регистру\n",
    "shares_pd[\"TRADE_CODE\"] = shares_pd[\"TRADE_CODE\"].str.lower()\n",
    "shares_pd[\"LIST_SECTION\"] = shares_pd[\"LIST_SECTION\"].str.replace(\" уровень\", \"\")\n",
    "shares_pd = shares_pd[[\"TRADE_CODE\", \"LIST_SECTION\"]]\n",
    "\n",
    "# загружаем список каналов\n",
    "channel_path = dir + \"TG\\\\\" + \"!channels\" + \".csv\"\n",
    "channels_df = pd.read_csv(\n",
    "    channel_path,\n",
    "    encoding=\"utf-8\",\n",
    "    sep=\"|\",\n",
    "    keep_default_na=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# статистика по корпусу конкретного канала. Параметр - наименование канала и число подписчиков\n",
    "\n",
    "def channel_load(channel):\n",
    "    channel_path = dir + \"TG\\\\\" + channel + \"_post.csv\"\n",
    "    # загрузка файла\n",
    "    load_df = pd.read_csv(\n",
    "        channel_path,\n",
    "        encoding=\"utf-8\",\n",
    "        sep=\"|\",\n",
    "        keep_default_na=False,\n",
    "    )\n",
    "    return load_df\n",
    "\n",
    "# статистическая обработка\n",
    "def corps_stat(channel, df, subsc, period_date):\n",
    "    # преобразуем поле с датой новости в тип ДАТА-ВРЕМЯ\n",
    "    df[\"NEWS_DATE\"] = pd.to_datetime(df[\"NEWS_DATE\"], dayfirst=False, errors=\"ignore\")\n",
    "    # крайние N дней\n",
    "    # period_date = 120\n",
    "    to_date = pd.to_datetime(\"today\").date()\n",
    "    from_date = to_date - pd.Timedelta(days=period_date)\n",
    "    from_date = from_date.strftime(\"%Y-%m-%d\")\n",
    "    to_date = to_date.strftime(\"%Y-%m-%d\")\n",
    "    # datetime.timedelta(days=30)\n",
    "    df_period = df[(df[\"NEWS_DATE\"] >= from_date) & (df[\"NEWS_DATE\"] < to_date)]\n",
    "    # распределение единичных постов по эшелонам тикеров (/уровень листинга)\n",
    "    shares_list = df_period[\n",
    "        (df_period[\"TICKERS\"].str.count(\",\") < 1) & (df_period[\"TICKERS\"] != \"\")\n",
    "    ][\"TICKERS\"]\n",
    "    shares_list_level = list()\n",
    "    for share in shares_list:\n",
    "        shares_list_level.append(\n",
    "            shares_pd[(shares_pd[\"TRADE_CODE\"] == share)][\"LIST_SECTION\"].values[0]\n",
    "        )\n",
    "    data = [\n",
    "        {\n",
    "            \"CHANNEL\": channel,\n",
    "            \"CHANNEL_SUBSC\": subsc,\n",
    "            \"CHANNEL_ALL_COUNT\": len(df),\n",
    "            \"CHANNEL_ALL_FROM\": df[\"NEWS_DATE\"].min().date(),\n",
    "            \"CHANNEL_ALL_TO\": df[\"NEWS_DATE\"].max().date(),\n",
    "            \"CHANNEL_PERIOD_FROM\": df_period[\"NEWS_DATE\"].min().date(),\n",
    "            \"CHANNEL_PERIOD_TO\": df_period[\"NEWS_DATE\"].max().date(),\n",
    "            \"CHANNEL_POST_DAY_COUNT\": round(len(df_period) / period_date, 2),\n",
    "            \"CHANNEL_POST_LEN\": int(df[\"NEWS_TEXT\"].str.len().mean()),\n",
    "            \"CHANNEL_POST_TOKENS\": len(\",\".join(df_period[\"WORDS\"]).split(\",\")),\n",
    "            \"CHANNEL_PERIOD_COUNT\": len(df_period),\n",
    "            \"CHANNEL_PERIOD_WITH_TICKERS\": len(df_period[(df_period[\"TICKERS\"] != \"\")]),\n",
    "            \"CHANNEL_PERIOD_ONE_TICKER\": len(\n",
    "                df_period[\n",
    "                    (df_period[\"TICKERS\"].str.count(\",\") < 1)\n",
    "                    & (df_period[\"TICKERS\"] != \"\")\n",
    "                ]\n",
    "            ),\n",
    "            \"CHANNEL_PERIOD_TOP_TICKERS\": \",\".join(\n",
    "                [\n",
    "                    word\n",
    "                    for word, word_count in Counter(\n",
    "                        list(\n",
    "                            df_period[\n",
    "                                (df_period[\"TICKERS\"].str.count(\",\") < 1)\n",
    "                                & (df_period[\"TICKERS\"] != \"\")\n",
    "                            ][\"TICKERS\"]\n",
    "                        )\n",
    "                    ).most_common(5)\n",
    "                ]\n",
    "            ),\n",
    "            \"CHANNEL_PERIOD_TOP_WORDS\": \",\".join(\n",
    "                [\n",
    "                    word\n",
    "                    for word, word_count in Counter(\n",
    "                        \",\".join(df_period[\"WORDS\"]).split(\",\")\n",
    "                    ).most_common(10)\n",
    "                ]\n",
    "            ),\n",
    "            \"CHANNEL_PERIOD_MOOD\": Counter(df_period[\"MOOD\"].values).most_common(3),\n",
    "            \"CHANNEL_PERIOD_TICKERS_LEVELS\": Counter(shares_list_level).most_common(3),\n",
    "            \"BIGRAMS\": Counter(\n",
    "                nltk.bigrams(\",\".join(df_period[\"WORDS\"]).split(\",\"))\n",
    "            ).most_common(10),\n",
    "            \"TRIGRAMS\": Counter(\n",
    "                nltk.trigrams(\",\".join(df_period[\"WORDS\"]).split(\",\"))\n",
    "            ).most_common(10),\n",
    "        }\n",
    "    ]\n",
    "    i_df = pd.DataFrame.from_dict(data)\n",
    "    return i_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# фрейм для каждого канала\n",
    "stat = pd.DataFrame()\n",
    "# фрейм для общего корпуса (/итого)\n",
    "load_df_big = pd.DataFrame()\n",
    "\n",
    "k = 0\n",
    "# print(\"Будет обработано: \",len(channels_df))\n",
    "for channel in channels_df[\"CHANNEL\"].values:\n",
    "    k += 1\n",
    "    # print(k, channel)\n",
    "    # количество подписчиков\n",
    "    subsc = channels_df[channels_df[\"CHANNEL\"] == channel][\"RELIABILITY\"].values[0]\n",
    "    # загружаем канал\n",
    "    load_df = channel_load(channel)\n",
    "    # отправляем его в статистическую обработку c количеством подписчиков и количеством дней\n",
    "    stat_df = corps_stat(channel, load_df, subsc, 400)\n",
    "    # сводим все каналы в один и статистический фрейм\n",
    "    stat = pd.concat([stat, stat_df], ignore_index=False)\n",
    "    # добавляем в общий корпус\n",
    "    load_df_big = pd.concat([load_df_big, load_df], ignore_index=False)\n",
    "\n",
    "# обрабатываем общий корпус\n",
    "stat_big_df = corps_stat(\"All\", load_df_big, \"\", 1000)\n",
    "\n",
    "pd.concat([stat_big_df, stat], ignore_index=False).to_html(\n",
    "     dir + \"Answers\\\\\" + \"0_Channels.html\"\n",
    ")\n",
    "# stat.to_html(dir + \"Answers\\\\\" + \"0_Channels.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_df_big\n",
    "# stat_big_df = corps_stat(\"All\",load_df_big, \"\", 3650)\n",
    "# stat_big_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
